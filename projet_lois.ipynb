{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet de lois \n",
    "Les projets de lois sont déposées par le gouvernement "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "URL type des projets de lois \n",
    "https://www.assemblee-nationale.fr/dyn/15/textes/l15b4324_projet-loi#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element not found\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B4324.html'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "name = soup.find('style=\"font-variant:small-caps\"', text='au nom de M. Jean CASTEX')\n",
    "if name:\n",
    "    next_sibling = name.find_next_sibling()\n",
    "    if next_sibling:\n",
    "        name = next_sibling.text\n",
    "        print(name)\n",
    "    else:\n",
    "        print(\"Next sibling element not found\")\n",
    "else:\n",
    "    print(\"Element not found\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping des projets de lois\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "URL type \n",
    "\n",
    "https://www.assemblee-nationale.fr/dyn/15/textes/l15bXXXX_projet-loi#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Récupération des numéro de projets de lois, date et exposée des motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "class TextInformation:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        response = requests.get(self.url)\n",
    "        self.soup = BeautifulSoup(response.text, 'html.parser', from_encoding='utf-8')\n",
    "    \n",
    "    def get_information(self):\n",
    "        information = self.soup.find('span', {'style': 'vertical-align:3pt'})\n",
    "\n",
    "        if information:\n",
    "            next_sibling = information.next_sibling\n",
    "            try:\n",
    "                return next_sibling.strip()\n",
    "            except AttributeError:\n",
    "                return \"No next sibling found\"\n",
    "        else:\n",
    "            return \"Element not found\"\n",
    "\n",
    "    \n",
    "    def get_date(self):\n",
    "        date = self.soup.find('p', {'class': 'assnatenregistr'})\n",
    "\n",
    "        if date:\n",
    "            date_text = date.text.strip()\n",
    "            words = date_text.split(\" \")\n",
    "            day = words[-3]\n",
    "            month = words[-2]\n",
    "            year = words[-1]\n",
    "            return f\"{day} {month} {year}\"\n",
    "        else:\n",
    "            return \"Element not found\"\n",
    "    \n",
    "    def get_texts(self):\n",
    "        texts = self.soup.find_all('p', {'class': 'assnatLoiTexte'})\n",
    "        if texts:\n",
    "            return [text.text.strip() for text in texts]\n",
    "        else:\n",
    "            return \"Elements not found\"\n",
    "            \n",
    "def clean_data(input_file, output_file):\n",
    "    # lecture des données\n",
    "    data = pd.read_csv(input_file)\n",
    "    to_analz = data.replace(regex=[r'\\\\xa0'], value=' ')\n",
    "    \n",
    "    # suppression du fichier existant s'il existe\n",
    "    if os.path.exists(output_file):\n",
    "        os.remove(output_file)\n",
    "\n",
    "    # enregistrement des données nettoyées dans un nouveau fichier csv\n",
    "    to_analz.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "def main(urls):\n",
    "    start_time = time.time()\n",
    "    result = []\n",
    "    with tqdm(total=len(urls), bar_format='{bar}') as pbar:\n",
    "        for url in urls:\n",
    "            pbar.update(1)\n",
    "            print(\"Processing: \", url)\n",
    "            text_info = TextInformation(url)\n",
    "            information = text_info.get_information()\n",
    "            if information == \"Element not found\":\n",
    "                continue\n",
    "            date = text_info.get_date()\n",
    "            texts = text_info.get_texts()\n",
    "            result.append([information, date, texts])\n",
    "\n",
    "    df = pd.DataFrame(result, columns=['Information', 'Date', 'Texts'])\n",
    "    df = df.replace(regex=[r'\\\\xa0'], value=' ')\n",
    "    \n",
    "    # suppression du fichier existant s'il existe\n",
    "    if os.path.exists('raw_data.csv'):\n",
    "        os.remove('raw_data.csv')\n",
    "\n",
    "    # enregistrement des données dans un fichier csv\n",
    "    df.to_csv('raw_data.csv', index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    # nettoyage des données et enregistrement dans un nouveau fichier csv\n",
    "    clean_data('raw_data.csv', 'to_analz.csv')\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    elapsed_time_minutes = round(elapsed_time / 60, 1)\n",
    "    print(\"--- %s minutes ---\" % (elapsed_time_minutes))\n",
    "\n",
    "\n",
    "\n",
    "urls = [f\"https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B{i:04d}.html\" for i in range(0, 5200) if i != 3651]\n",
    "main(urls)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Récupération des articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "– 1 –\n",
      "\n",
      "\n",
      "\n",
      "projet de loi\n",
      "\n",
      "\n",
      "\t\t\t\tLe Premier ministre,\n",
      "\t\t\t\n",
      "\n",
      "\t\t\t\tSur le rapport de la ministre des solidarités et de la santé,\n",
      "\t\t\t\n",
      "\n",
      "\t\t\t\tVu l’article 39 de la Constitution,\n",
      "\t\t\t\n",
      "\n",
      "\t\t\t\tDécrète :\n",
      "\t\t\t\n",
      "\n",
      "Le présent projet de loi ratifiant l’ordonnance n° 2017‑484 du 6 avril 2017 relative à la création d’organismes dédiés à l’exercice de l’activité de retraite professionnelle supplémentaire et à l’adaptation des régimes de retraite supplémentaire en unités de rente, délibéré en conseil des ministres après avis du Conseil d’État, sera présenté à l’Assemblée nationale par le ministre de l’économie et des finances, qui sera chargé d’en exposer les motifs et d’en soutenir la discussion.\n",
      "\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Article 1er\n",
      "\n",
      "\n",
      "\t\t\t\tL’ordonnance n° 2017‑484 du 6 avril 2017 relative à la création d’organismes dédiés à l’exercice de l’activité de retraite professionnelle supplémentaire et à l’adaptation des régimes de retraite supplémentaire en unités de rente est ratifiée.\n",
      "\t\t\t\n",
      "\n",
      "Article 2\n",
      "\n",
      "\n",
      "Le chapitre III du titre II du livre IV du code des assurances est ainsi modifié :\n",
      "\t\t\t\n",
      "\n",
      "1° L’article L. 423‑1 est ainsi modifié : \n",
      "\t\t\t\n",
      "\n",
      "a) Au a, après le mot : « entreprise » sont insérés les mots : « ou du fonds de retraite professionnelle supplémentaire » ; \n",
      "\t\t\t\n",
      "\n",
      "b) Au d, après le mot : « assurance » sont insérés les mots : « ou le fonds de retraite professionnelle supplémentaire » ;\n",
      "\t\t\t\n",
      "\n",
      "2° L’article L. 423‑2 est ainsi modifié :\n",
      "\t\t\t\n",
      "\n",
      "a) Au premier alinéa du I, les mots : « entreprise mentionnée à l’article L. 423‑1 du présent code » sont remplacés par les mots : « personne mentionnée au premier alinéa de l’article L. 423‑1 » ;\n",
      "\t\t\t\n",
      "\n",
      "b) À la première phrase du dernier alinéa du I, le mot : « concernée » est remplacé par les mots : « ou au fonds de retraite professionnelle supplémentaire concerné » ;\n",
      "\t\t\t\n",
      "\n",
      "c) La première phrase du V est complétée par les mots : « ou du fonds de retraite professionnelle supplémentaire défaillant » ;\n",
      "\t\t\t\n",
      "\n",
      "3° L’article L. 423‑4 est ainsi modifié :\n",
      "\t\t\t\n",
      "\n",
      "a) Au quatrième alinéa, les mots : « les entreprises adhérentes » sont remplacés par les mots : « les entreprises ou fonds de retraite professionnelle supplémentaire adhérents » et la deuxième occurrence du mot : « entreprises » est remplacée par le mot : « adhérents » ;\n",
      "\t\t\t\n",
      "\n",
      "b) Au quatrième alinéa, après les mots : « d’entreprises d’assurance soumises au présent code » sont insérés les mots : « et des fonds de retraite professionnelle supplémentaire » ;\n",
      "\t\t\t\n",
      "\n",
      "c) À la deuxième phrase du cinquième alinéa, après le mot : « entreprises » sont insérés les mots : « ou des fonds de retraite professionnelle supplémentaire » ;\n",
      "\t\t\t\n",
      "\n",
      "d) Après le mot : « entreprises », la fin de la deuxième phrase du sixième alinéa est ainsi rédigée : « ou des fonds de retraite professionnelle supplémentaire adhérents, ni recevoir de rétribution de l’un d’eux. » ;\n",
      "\t\t\t\n",
      "\n",
      "e) Au huitième alinéa, les mots : « pour laquelle » sont remplacés les mots : « ou un fonds de retraite professionnelle supplémentaire pour lequel » ; \n",
      "\t\t\t\n",
      "\n",
      "4° L’article L. 423‑5 est ainsi modifié : \n",
      "\t\t\t\n",
      "\n",
      "a) Au deuxième alinéa, après le mot : « défaillante » sont insérés les mots : « ou du fonds de retraite professionnelle supplémentaire défaillant » ;\n",
      "\t\t\t\n",
      "\n",
      "b) À la première phrase du dernier alinéa, après le mot : « assurance » sont insérés les mots : « ou du fonds de retraite professionnelle supplémentaire » ;\n",
      "\t\t\t\n",
      "\n",
      "5° Au premier alinéa de l’article L. 423‑7, les mots : « établissements adhérant » et les mots : « entreprises adhérentes » sont remplacés par le mot : « adhérents » ;\n",
      "\t\t\t\n",
      "\n",
      "6° L’article L. 423‑8 est ainsi modifié : \n",
      "\t\t\t\n",
      "\n",
      "a) Le troisième alinéa est complété par les mots : « ou du fonds de retraite professionnelle supplémentaire défaillant » ;\n",
      "\t\t\t\n",
      "\n",
      "b) Au cinquième alinéa, les mots : « entreprises adhérentes » sont remplacés par le mot : « adhérents ».\n",
      "\t\t\t\n",
      "\n",
      "Article 3\n",
      "\n",
      "\n",
      "Le chapitre Ier du titre III du livre IV du code de la mutualité est ainsi modifié :\n",
      "\t\t\t\n",
      "\n",
      "1° L’article L. 431‑1 est ainsi modifié : \n",
      "\t\t\t\n",
      "\n",
      "a) Au a, les mots : « ou de l’union » sont remplacés à chacune des deux occurrences par les mots : « , de l’union ou de la mutuelle ou union de retraite professionnelle supplémentaire » et les mots : « ou union » sont remplacés par les mots : « , union ou mutuelle ou union de retraite professionnelle supplémentaire » ;\n",
      "\t\t\t\n",
      "\n",
      "b) Au c, après le mot : « unions, », sont insérés les mots : « mutuelles ou unions de retraite professionnelle supplémentaire, » ;\n",
      "\t\t\t\n",
      "\n",
      "2° L’article L. 431‑2 est ainsi modifié : \n",
      "\t\t\t\n",
      "\n",
      "a) Après le mot : « mutuelle », la fin de la première phrase du dernier alinéa du I est ainsi rédigée : « , l’union ou la mutuelle ou union de retraite professionnelle supplémentaire concernée » ; \n",
      "\t\t\t\n",
      "\n",
      "b) À la première phrase du V, les mots : « ou de l’union » sont remplacés par les mots : « , de l’union ou de la mutuelle ou union de retraite professionnelle supplémentaire » ;\n",
      "\t\t\t\n",
      "\n",
      "3° L’article L. 431‑4 est ainsi modifié : \n",
      "\t\t\t\n",
      "\n",
      "a) À la deuxième phrase du sixième alinéa, les mots : « ou d’unions » sont remplacés par les mots : « , d’unions ou de mutuelles ou unions de retraite professionnelle supplémentaire » ;\n",
      "\t\t\t\n",
      "\n",
      "b) Au huitième alinéa, les mots : « ou une union » sont remplacés par les mots : « , une union ou une mutuelle ou union de retraite professionnelle supplémentaire » ;\n",
      "\t\t\t\n",
      "\n",
      "4° À la première phrase du dernier alinéa de l’article L. 431‑5, les mots : « ou de l’union » sont remplacés par les mots : « , de l’union ou de la mutuelle ou union de retraite professionnelle supplémentaire » ;\n",
      "\t\t\t\n",
      "\n",
      "5° Au premier alinéa de l’article L. 431‑7, les mots : « mutuelles et unions » sont remplacés par le mot : « organismes » ; \n",
      "\t\t\t\n",
      "\n",
      "6° Au 4° de l’article L. 431‑8, les mots : « mutuelles et unions » sont remplacés par le mot : « organismes ».\n",
      "\t\t\t\n",
      "\n",
      "Article 4\n",
      "\n",
      "\n",
      "Le livre IX du code de la sécurité sociale est ainsi modifié :\n",
      "\t\t\t\n",
      "\n",
      "1° L’article L. 931‑37 est ainsi modifié :\n",
      "\t\t\t\n",
      "\n",
      "a) La première phrase du premier alinéa est complétée par les mots : « , de leurs unions ou d’institutions de retraite professionnelle supplémentaire » ;\n",
      "\t\t\t\n",
      "\n",
      "b) Au troisième alinéa, les mots : « ou d’une union d’institutions de prévoyance » sont remplacés par les mots : « , d’une union d’institutions de prévoyance ou d’une institution de retraite professionnelle supplémentaire » ;\n",
      "\t\t\t\n",
      "\n",
      "2° Au 3° de l’article L. 931‑38, les mots : « et unions » sont remplacés par les mots : « , unions et institutions de retraite professionnelle supplémentaire » ;\n",
      "\t\t\t\n",
      "\n",
      "3° À la première phrase du dernier alinéa de l’article L. 931‑39, les mots : « ou de l’union » sont remplacés par les mots : « , de l’union ou de l’institution de retraite professionnelle supplémentaire » ; \n",
      "\t\t\t\n",
      "\n",
      "4° L’article L. 931‑41 est ainsi modifié : \n",
      "\t\t\t\n",
      "\n",
      "a) Au premier alinéa, les mots : « et unions » sont remplacés par les mots : « , unions et institutions de retraite professionnelle supplémentaire » ; \n",
      "\t\t\t\n",
      "\n",
      "b) Au deuxième alinéa, les mots : « ou unions » sont remplacés par les mots : « , unions ou institutions de retraite professionnelle supplémentaire » ;\n",
      "\t\t\t\n",
      "\n",
      "5° Au 1° de l’article L. 931‑42, les mots : « ou unions » sont remplacés par les mots : « , unions ou institutions de retraite professionnelle supplémentaire » ;\n",
      "\t\t\t\n",
      "\n",
      "6° À la première phrase du premier alinéa du I de l’article L. 951‑2, les mots : « ou d’une union d’institutions de prévoyance » sont remplacés par les mots : « , d’une union ou d’une institution de retraite professionnelle supplémentaire » ;\n",
      "\t\t\t\n",
      "\n",
      "7° Au premier alinéa de l’article L. 951‑11, les mots : « ou d’une société de groupe assurantiel de protection sociale ou d’une union d’institution de prévoyance » sont remplacés par les mots : « , d’une institution de retraite professionnelle supplémentaire ou d’une société de groupe assurantiel de protection sociale, ».\n",
      "\t\t\t\n",
      "\n",
      "\t\t\t\t \n",
      "\t\t\t\n",
      "\n",
      "\t\t\t\t \n",
      "\t\t\t\n",
      "\n",
      "\t\t\t\tFait à Paris, le 29 juin 2017.\n",
      "\t\t\t\n",
      "\n",
      "Signé : Édouard PHILIPPE\n",
      "\t\t\t\n",
      "\n",
      "\t\t\t\t \n",
      "\t\t\t\n",
      "\n",
      "\t\t\t\t \n",
      "\t\t\t\n",
      "\n",
      "\t\t\t\t \n",
      "\t\t\t\n",
      "\n",
      "\t\t\t\t \n",
      "\t\t\t\n",
      "\n",
      "\t\t\t\t \n",
      "\t\t\t\n",
      "\n",
      "\t\t\t\t \n",
      "\t\t\t\n",
      "\n",
      "\t\t\t\t \n",
      "\t\t\t\n",
      "\n",
      "\t\t\t\t \n",
      "\t\t\t\n",
      "\n",
      "\t\t\t\t \n",
      "\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\tPar le Premier ministre :Le ministre de l’économie et des finances,Signé : Bruno LE MAIRE\n",
      "\t\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t \n",
      "\t\t\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importer les bibliothèques nécessaires\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# Obtenir le contenu HTML de la page web\n",
    "\n",
    "response = requests.get(url)\n",
    "html_content = response.text\n",
    "\n",
    "# Analyser le contenu HTML avec BeautifulSoup\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Trouver la balise <div class=\"assnatSection3\">\n",
    "section3 = soup.find('div', {'class': 'assnatSection3'})\n",
    "\n",
    "# Récupérer tout le texte contenu dans la balise\n",
    "texte = section3.text\n",
    "\n",
    "# Afficher le texte récupéré\n",
    "print(texte)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "████      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B3735.html\n",
      "Error getting information from https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B3735.html\n",
      "Processing:  https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B3736.html\n",
      "Error getting information from https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B3736.html\n",
      "Processing:  https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B3737.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "████████  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error getting information from https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B3737.html\n",
      "Processing:  https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B3738.html\n",
      "Error getting information from https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B3738.html\n",
      "Processing:  https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B3739.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "██████████"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error getting information from https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B3739.html\n",
      "--- 0.0 minutes ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class TextInformation:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        response = requests.get(self.url)\n",
    "        self.soup = BeautifulSoup(response.text, 'html.parser', from_encoding='utf-8')\n",
    "    \n",
    "    def get_information(self):\n",
    "        \"\"\"Get the information from the webpage\"\"\"\n",
    "        try:\n",
    "            soup = self.get_soup()\n",
    "            information = soup.find(\"div\", class_=\"titre\")\n",
    "            next_sibling = information.next_sibling\n",
    "            while next_sibling is not None:\n",
    "                if next_sibling.name == \"h3\":\n",
    "                    break\n",
    "                next_sibling = next_sibling.next_sibling\n",
    "            if next_sibling is not None:\n",
    "                try:\n",
    "                    return next_sibling.text.strip()\n",
    "                except AttributeError:\n",
    "                    pass\n",
    "            else:\n",
    "                print(\"Error: next sibling is None\")\n",
    "        except:\n",
    "            print(f\"Error getting information from {self.url}\")\n",
    "\n",
    "\n",
    "\n",
    "    def get_date(self):\n",
    "        date = self.soup.find('p', {'class': 'assnatenregistr'})\n",
    "\n",
    "        if date:\n",
    "            date_text = date.text.strip()\n",
    "            words = date_text.split(\" \")\n",
    "            day = words[-3]\n",
    "            month = words[-2]\n",
    "            year = words[-1]\n",
    "            return f\"{day} {month} {year}\"\n",
    "        return None\n",
    "\n",
    "    def get_texts(self):\n",
    "        texts = self.soup.find_all('p', {'class': 'assnatLoiTexte'})\n",
    "        if texts:\n",
    "            return [text.text.strip() for text in texts]\n",
    "        return None\n",
    "\n",
    "\n",
    "def clean_data(input_file, output_file):\n",
    "    # lecture des données\n",
    "    data = pd.read_csv(input_file)\n",
    "    to_analz_2 = data.replace(regex=[r'\\\\xa0'], value=' ')\n",
    "\n",
    "    # suppression du fichier existant s'il existe\n",
    "    if os.path.exists(output_file):\n",
    "        os.remove(output_file)\n",
    "\n",
    "    # enregistrement des données nettoyées dans un nouveau fichier csv\n",
    "    to_analz_2.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "def main(urls):\n",
    "    start_time = time.time()\n",
    "    result = []\n",
    "    with tqdm(total=len(urls), bar_format='{bar}') as pbar:\n",
    "        for url in urls:\n",
    "            pbar.update(1)\n",
    "            print(\"Processing: \", url)\n",
    "            text_info = TextInformation(url)\n",
    "            information = text_info.get_information()\n",
    "            date = text_info.get_date()\n",
    "            texts = text_info.get_texts()\n",
    "            if information is not None and date is not None and texts is not None:\n",
    "                result.append([information, date, texts])\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    df = pd.DataFrame(result, columns=['Information', 'Date', 'expose_lois'])\n",
    "    df = df.replace(regex=[r'\\\\xa0'], value=' ')\n",
    "\n",
    "    # suppression du fichier existant s'il existe\n",
    "    if os.path.exists('raw_data_2.csv'):\n",
    "        os.remove('raw_data_2.csv')\n",
    "\n",
    "    # enregistrement des données dans un fichier csv\n",
    "    df.to_csv('raw_data_2.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "    # nettoyage des données et enregistrement dans un nouveau fichier csv\n",
    "    clean_data('raw_data_2.csv', 'to_analz_2.csv')\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    elapsed_time_minutes = round(elapsed_time / 60, 1)\n",
    "    print(\"--- %s minutes ---\" % (elapsed_time_minutes))\n",
    "\n",
    "\n",
    "urls = [f\"https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B{i:04d}.html\" for i in range(3735, 3740)]\n",
    "main(urls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/Users/camille/repo/Hetic/projet_demo/ia_theme_French National Assembly/scraping/cleaned_data.csv')\n",
    "df = df.replace(regex=[r'\\\"\\[\\''], value='')\n",
    "df = df.replace(regex=[r'\\\"'], value='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/camille/repo/notebook_env/lib/python3.10/site-packages/bs4/__init__.py:226: UserWarning: You provided Unicode markup but also provided a value for from_encoding. Your from_encoding will be ignored.\n",
      "  warnings.warn(\"You provided Unicode markup but also provided a value for from_encoding. Your from_encoding will be ignored.\")\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  https://www.assemblee-nationale.fr/dyn/opendata/PRJANR5L15B0003.html\n",
      "Error getting information from https://www.assemblee-nationale.fr/dyn/opendata/PRJANR5L15B0003.html\n",
      "Processing time: 0.12 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class TextInformation:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        response = requests.get(self.url)\n",
    "        self.soup = BeautifulSoup(\n",
    "            response.text,\n",
    "            'html.parser',\n",
    "            from_encoding='utf-8')\n",
    "\n",
    "    def get_information(self):\n",
    "        \"\"\"Get the information from the webpage\"\"\"\n",
    "        try:\n",
    "            soup = self.soup\n",
    "            # On a déjà stocké self.soup dans l'initialisation, on peut donc le réutiliser directement\n",
    "            information = self.soup.find('span', {'style': 'vertical-align:3pt'})\n",
    "\n",
    "            next_sibling = information.next_sibling\n",
    "            if next_sibling is not None:\n",
    "                try:\n",
    "                    return next_sibling.text.strip()\n",
    "                except AttributeError:\n",
    "                    pass\n",
    "            else:\n",
    "                print(\"Error: next sibling is None\")\n",
    "        except BaseException:\n",
    "            print(f\"Error getting information from {self.url}\")\n",
    "\n",
    "    def get_date(self):\n",
    "        date = self.soup.find('p', {'class': 'assnatenregistr'})\n",
    "\n",
    "        if date:\n",
    "            date_text = date.text.strip()\n",
    "            words = date_text.split(\" \")\n",
    "            day = words[-3]\n",
    "            month = words[-2]\n",
    "            year = words[-1]\n",
    "            return f\"{day} {month} {year}\"\n",
    "        return None\n",
    "\n",
    "    def get_texts(self):\n",
    "        texts = self.soup.find_all('p', {'class': 'assnatLoiTexte'})\n",
    "        if texts:\n",
    "            return [text.text.strip() for text in texts]\n",
    "        return None\n",
    "    \n",
    "    def get_helo(self):\n",
    "        section3 = self.soup.find('div', {'class': 'assnatSection3'})\n",
    "        if section3:\n",
    "            return   [text.text.strip() for text in section3]\n",
    "        return None\n",
    "    \n",
    "    def clean_data(self, input_file, output_file):\n",
    "        # lecture des données\n",
    "        data = pd.read_csv(input_file)\n",
    "        to_analz_2 = data.replace(regex=[r'\\\"\\[\\''], value='').replace(regex=[r'\\'\\]\\\"'], value='').replace(regex=[r'\\\\xa0'], value=' ')\n",
    "\n",
    "        # suppression du fichier existant s'il existe\n",
    "        if os.path.exists(output_file):\n",
    "            os.remove(output_file)\n",
    "\n",
    "        # appliquer la même transformation sur to_analz_2\n",
    "        to_analz_2 = to_analz_2.replace(regex=[r'\\\"\\[\\''], value='').replace(regex=[r'\\'\\]\\\"'], value='').replace(regex=[r'\\\\xa0'], value=' ')\n",
    "\n",
    "        # enregistrement des données nettoyées dans un nouveau fichier csv\n",
    "        to_analz_2.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "        \n",
    "    def main(self):\n",
    "        start_time = time.time()\n",
    "        result = []\n",
    "        for url in tqdm([self.url]):\n",
    "            print(\"Processing: \", url)\n",
    "            text_info = TextInformation(url)\n",
    "            information = text_info.get_information()\n",
    "            date = text_info.get_date()\n",
    "            texts = text_info.get_texts()\n",
    "            helo = text_info.get_helo()\n",
    "            if information is not None and date is not None and texts is not None and helo is not None:\n",
    "                result.append([information, date, texts, helo])\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        df = pd.DataFrame(result, columns=['Information', 'Date', 'exposee', 'texte_lois'])\n",
    "        df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/camille/repo/notebook_env/lib/python3.10/site-packages/bs4/__init__.py:226: UserWarning: You provided Unicode markup but also provided a value for from_encoding. Your from_encoding will be ignored.\n",
      "  warnings.warn(\"You provided Unicode markup but also provided a value for from_encoding. Your from_encoding will be ignored.\")\n",
      " 33%|███▎      | 1/3 [00:00<00:00,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  https://www.assemblee-nationale.fr/dyn/opendata/PRJANR5L15B0003.html\n",
      "Error getting information from https://www.assemblee-nationale.fr/dyn/opendata/PRJANR5L15B0003.html\n",
      "Processing:  https://www.assemblee-nationale.fr/dyn/opendata/PRJANR5L15B0004.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error getting information from https://www.assemblee-nationale.fr/dyn/opendata/PRJANR5L15B0004.html\n",
      "Processing:  https://www.assemblee-nationale.fr/dyn/opendata/PRJANR5L15B0005.html\n",
      "Error getting information from https://www.assemblee-nationale.fr/dyn/opendata/PRJANR5L15B0005.html\n",
      "Processing time: 0.56 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "urls = [    'https://www.assemblee-nationale.fr/dyn/opendata/PRJANR5L15B0003.html',    'https://www.assemblee-nationale.fr/dyn/opendata/PRJANR5L15B0004.html',    'https://www.assemblee-nationale.fr/dyn/opendata/PRJANR5L15B0005.html']\n",
    "\n",
    "text_info = TextInformation(urls[0])\n",
    "text_info.main(urls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls =  'https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0003.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:00<00:03,  8.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0000.html\n",
      "Error getting information from https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0000.html\n",
      "Processing:  https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0001.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [00:00<00:03,  8.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error getting information from https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0001.html\n",
      "Processing:  https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0002.html\n",
      "Error getting information from https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0002.html\n",
      "Processing:  https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0003.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [00:00<00:04,  6.31it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/camille/repo/Hetic/projet_demo/ia_theme_French National Assembly/scraping/projet_lois.ipynb Cell 15\u001b[0m in \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/camille/repo/Hetic/projet_demo/ia_theme_French%20National%20Assembly/scraping/projet_lois.ipynb#X15sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m urls \u001b[39m=\u001b[39m [\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhttps://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m:\u001b[39;00m\u001b[39m04d\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.html\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/camille/repo/Hetic/projet_demo/ia_theme_French%20National%20Assembly/scraping/projet_lois.ipynb#X15sZmlsZQ%3D%3D?line=100'>101</a>\u001b[0m     \u001b[39m0\u001b[39m, \u001b[39m30\u001b[39m)]\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/camille/repo/Hetic/projet_demo/ia_theme_French%20National%20Assembly/scraping/projet_lois.ipynb#X15sZmlsZQ%3D%3D?line=101'>102</a>\u001b[0m scraper \u001b[39m=\u001b[39m WebScraper(urls)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/camille/repo/Hetic/projet_demo/ia_theme_French%20National%20Assembly/scraping/projet_lois.ipynb#X15sZmlsZQ%3D%3D?line=102'>103</a>\u001b[0m scraper\u001b[39m.\u001b[39;49mscrape()\n",
      "\u001b[1;32m/Users/camille/repo/Hetic/projet_demo/ia_theme_French National Assembly/scraping/projet_lois.ipynb Cell 15\u001b[0m in \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/camille/repo/Hetic/projet_demo/ia_theme_French%20National%20Assembly/scraping/projet_lois.ipynb#X15sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m helo \u001b[39m=\u001b[39m text_info\u001b[39m.\u001b[39mget_helo()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/camille/repo/Hetic/projet_demo/ia_theme_French%20National%20Assembly/scraping/projet_lois.ipynb#X15sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m \u001b[39mif\u001b[39;00m information \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m date \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m texts \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m helo \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/camille/repo/Hetic/projet_demo/ia_theme_French%20National%20Assembly/scraping/projet_lois.ipynb#X15sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(result, columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mInformation\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mDate\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mexposee\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtexte_lois\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/camille/repo/Hetic/projet_demo/ia_theme_French%20National%20Assembly/scraping/projet_lois.ipynb#X15sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m     df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mreplace(regex\u001b[39m=\u001b[39m[\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m[\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39m'\u001b[39m], value\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mreplace(regex\u001b[39m=\u001b[39m[\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39m\\\u001b[39m\u001b[39m]\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m], value\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mreplace(regex\u001b[39m=\u001b[39m[\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mxa0\u001b[39m\u001b[39m'\u001b[39m], value\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/camille/repo/Hetic/projet_demo/ia_theme_French%20National%20Assembly/scraping/projet_lois.ipynb#X15sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m     header \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39murl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39minformation\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtexts\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mhelo\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "class TextInformation:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        response = requests.get(self.url)\n",
    "        self.soup = BeautifulSoup(\n",
    "            response.text,\n",
    "            'html.parser',\n",
    "            from_encoding='utf-8')\n",
    "\n",
    "    def get_information(self):\n",
    "        \"\"\"Get the information from the webpage\"\"\"\n",
    "        try:\n",
    "            soup = self.soup\n",
    "            # On a déjà stocké self.soup dans l'initialisation, on peut donc le réutiliser directement\n",
    "            information = self.soup.find('span', {'style': 'vertical-align:3pt'})\n",
    "\n",
    "            next_sibling = information.next_sibling\n",
    "            if next_sibling is not None:\n",
    "                try:\n",
    "                    return next_sibling.text.strip()\n",
    "                except AttributeError:\n",
    "                    pass\n",
    "            else:\n",
    "                print(\"Error: next sibling is None\")\n",
    "        except BaseException:\n",
    "            print(f\"Error getting information from {self.url}\")\n",
    "\n",
    "    def get_date(self):\n",
    "        date = self.soup.find('p', {'class': 'assnatenregistr'})\n",
    "\n",
    "        if date:\n",
    "            date_text = date.text.strip()\n",
    "            words = date_text.split(\" \")\n",
    "            day = words[-3]\n",
    "            month = words[-2]\n",
    "            year = words[-1]\n",
    "            return f\"{day} {month} {year}\"\n",
    "        return None\n",
    "\n",
    "    def get_texts(self):\n",
    "        texts = self.soup.find_all('p', {'class': 'assnatLoiTexte'})\n",
    "        if texts:\n",
    "            return [text.text.strip() for text in texts]\n",
    "        return None\n",
    "    \n",
    "    def get_helo(self):\n",
    "        section3 = self.soup.find('div', {'class': 'assnatSection3'})\n",
    "        if section3:\n",
    "            return   [text.text.strip() for text in section3]\n",
    "        return None\n",
    "    \n",
    "class DataCleaner:\n",
    "    def __init__(self, input_file, output_file):\n",
    "        self.input_file = input_file\n",
    "        self.output_file = output_file\n",
    "        \n",
    "    def clean_data(self):\n",
    "        # lecture des données\n",
    "        data = pd.read_csv(self.input_file)\n",
    "        to_analz_2 = data.replace(regex=[r'\\\"\\[\\''], value='').replace(regex=[r'\\'\\]\\\"'], value='').replace(regex=[r'\\\\xa0'], value=' ')\n",
    "\n",
    "        # suppression du fichier existant s'il existe\n",
    "        if os.path.exists(self.output_file):\n",
    "            os.remove(self.output_file)\n",
    "\n",
    "        # appliquer la même transformation sur to_analz_2\n",
    "        to_analz_2 = to_analz_2.replace(regex=[r'\\\"\\[\\''], value='').replace(regex=[r'\\'\\]\\\"'], value='').replace(regex=[r'\\\\xa0'], value=' ')\n",
    "\n",
    "        # enregistrement des données nettoyées dans un nouveau fichier csv\n",
    "        to_analz_2.to_csv(self.output_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "class WebScraper:\n",
    "    def __init__(self, urls):\n",
    "        self.urls = urls\n",
    "        self.result = []\n",
    "        \n",
    "    def scrape(self):\n",
    "        for url in tqdm(self.urls):\n",
    "            print(\"Processing: \", url)\n",
    "            text_info = TextInformation(url)\n",
    "            information = text_info.get_information()\n",
    "            date = text_info.get_date()\n",
    "            texts = text_info.get_texts()\n",
    "            helo = text_info.get_helo()\n",
    "            if information is not None and date is not None and texts is not None and helo is not None:\n",
    "                df = pd.DataFrame(result, columns=['Information', 'Date', 'exposee', 'texte_lois'])\n",
    "                df = df.replace(regex=[r'\\\"\\[\\''], value='').replace(regex=[r'\\'\\]\\\"'], value='').replace(regex=[r'\\\\xa0'], value=' ')\n",
    "                header = ['url', 'information', 'date', 'texts', 'helo']\n",
    "                df = pd.DataFrame(scraper.result, columns=header)\n",
    "                df.to_csv('result.csv', mode='a', index=False, header=False, encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "urls = [f\"https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B{i:04d}.html\" for i in range(\n",
    "    0, 30)]\n",
    "scraper = WebScraper(urls)\n",
    "scraper.scrape()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "urls = [f\"https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B{i:04d}.html\" for i in range(\n",
    "    0, 30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Information</th>\n",
       "      <th>Date</th>\n",
       "      <th>exposee</th>\n",
       "      <th>texte_lois</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>29 juin 2017.</td>\n",
       "      <td>['L’article 114 de la loi n° 2016‑1691 du 9 dé...</td>\n",
       "      <td>['', '– 1 –', '', 'projet de loi', '', 'Le Pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>29 juin 2017.</td>\n",
       "      <td>['Conformément à la volonté du Président de la...</td>\n",
       "      <td>['', '– 1 –', '', 'projet de loi', '', 'Le Pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>29 juin 2017.</td>\n",
       "      <td>['', 'Le présent projet de loi ratifiant l’ord...</td>\n",
       "      <td>['', 'projet de loi', '', 'Le Premier ministre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>29 juin 2017.</td>\n",
       "      <td>['L’article 1er du projet de loi ratifie l’ord...</td>\n",
       "      <td>['', '– 1 –', '', 'projet de loi', '', 'Le Pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>29 juin 2017.</td>\n",
       "      <td>['L’article unique du projet de loi procède à ...</td>\n",
       "      <td>['', 'projet de loi', '', 'Le Premier ministre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2 février 2022.</td>\n",
       "      <td>['L’article 74 de la loi n° 2019‑1428 du 24 dé...</td>\n",
       "      <td>['', 'projet de loi', '', 'Le Premier ministre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>NaN</td>\n",
       "      <td>23 février 2022.</td>\n",
       "      <td>['L’article 55 de la loi n° 2019‑828 du 6 août...</td>\n",
       "      <td>['', '– 1 –', '', 'projet de loi', '', 'Le Pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7 mars 2022.</td>\n",
       "      <td>['ratifiant l’ordonnance n° 2021‑1200 du 15 se...</td>\n",
       "      <td>['', 'projet de loi', '', 'Le Premier ministre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9 mars 2022.</td>\n",
       "      <td>['L’article 108 de la loi n° 2020‑1576 du 14 d...</td>\n",
       "      <td>['', 'projet de loi', '', 'Le Premier ministre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>NaN</td>\n",
       "      <td>16 mars 2022.</td>\n",
       "      <td>['L’action du ministère de l’intérieur est au ...</td>\n",
       "      <td>['', 'projet de loi', '', 'Le Premier ministre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>271 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Information              Date  \\\n",
       "0             3     29 juin 2017.   \n",
       "1             4     29 juin 2017.   \n",
       "2             6     29 juin 2017.   \n",
       "3             7     29 juin 2017.   \n",
       "4             8     29 juin 2017.   \n",
       "..          ...               ...   \n",
       "266         NaN   2 février 2022.   \n",
       "267         NaN  23 février 2022.   \n",
       "268         NaN      7 mars 2022.   \n",
       "269         NaN      9 mars 2022.   \n",
       "270         NaN     16 mars 2022.   \n",
       "\n",
       "                                               exposee  \\\n",
       "0    ['L’article 114 de la loi n° 2016‑1691 du 9 dé...   \n",
       "1    ['Conformément à la volonté du Président de la...   \n",
       "2    ['', 'Le présent projet de loi ratifiant l’ord...   \n",
       "3    ['L’article 1er du projet de loi ratifie l’ord...   \n",
       "4    ['L’article unique du projet de loi procède à ...   \n",
       "..                                                 ...   \n",
       "266  ['L’article 74 de la loi n° 2019‑1428 du 24 dé...   \n",
       "267  ['L’article 55 de la loi n° 2019‑828 du 6 août...   \n",
       "268  ['ratifiant l’ordonnance n° 2021‑1200 du 15 se...   \n",
       "269  ['L’article 108 de la loi n° 2020‑1576 du 14 d...   \n",
       "270  ['L’action du ministère de l’intérieur est au ...   \n",
       "\n",
       "                                            texte_lois  \n",
       "0    ['', '– 1 –', '', 'projet de loi', '', 'Le Pre...  \n",
       "1    ['', '– 1 –', '', 'projet de loi', '', 'Le Pre...  \n",
       "2    ['', 'projet de loi', '', 'Le Premier ministre...  \n",
       "3    ['', '– 1 –', '', 'projet de loi', '', 'Le Pre...  \n",
       "4    ['', 'projet de loi', '', 'Le Premier ministre...  \n",
       "..                                                 ...  \n",
       "266  ['', 'projet de loi', '', 'Le Premier ministre...  \n",
       "267  ['', '– 1 –', '', 'projet de loi', '', 'Le Pre...  \n",
       "268  ['', 'projet de loi', '', 'Le Premier ministre...  \n",
       "269  ['', 'projet de loi', '', 'Le Premier ministre...  \n",
       "270  ['', 'projet de loi', '', 'Le Premier ministre...  \n",
       "\n",
       "[271 rows x 4 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/camille/repo/Hetic/projet_demo/ia_theme_French National Assembly/scraping/cleaned_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Information</th>\n",
       "      <th>Date</th>\n",
       "      <th>exposee</th>\n",
       "      <th>texte_lois</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>29 juin 2017.</td>\n",
       "      <td>L’article 114 de la loi n° 2016‑1691 du 9 déce...</td>\n",
       "      <td>', '– 1 –', '', 'projet de loi', '', 'Le Premi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>29 juin 2017.</td>\n",
       "      <td>Conformément à la volonté du Président de la R...</td>\n",
       "      <td>', '– 1 –', '', 'projet de loi', '', 'Le Premi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>29 juin 2017.</td>\n",
       "      <td>', 'Le présent projet de loi ratifiant l’ordon...</td>\n",
       "      <td>', 'projet de loi', '', 'Le Premier ministre,'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>29 juin 2017.</td>\n",
       "      <td>L’article 1er du projet de loi ratifie l’ordon...</td>\n",
       "      <td>', '– 1 –', '', 'projet de loi', '', 'Le Premi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>29 juin 2017.</td>\n",
       "      <td>L’article unique du projet de loi procède à la...</td>\n",
       "      <td>', 'projet de loi', '', 'Le Premier ministre,'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2 février 2022.</td>\n",
       "      <td>L’article 74 de la loi n° 2019‑1428 du 24 déce...</td>\n",
       "      <td>', 'projet de loi', '', 'Le Premier ministre,'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>NaN</td>\n",
       "      <td>23 février 2022.</td>\n",
       "      <td>L’article 55 de la loi n° 2019‑828 du 6 août 2...</td>\n",
       "      <td>', '– 1 –', '', 'projet de loi', '', 'Le Premi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7 mars 2022.</td>\n",
       "      <td>ratifiant l’ordonnance n° 2021‑1200 du 15 sept...</td>\n",
       "      <td>', 'projet de loi', '', 'Le Premier ministre,'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9 mars 2022.</td>\n",
       "      <td>L’article 108 de la loi n° 2020‑1576 du 14 déc...</td>\n",
       "      <td>', 'projet de loi', '', 'Le Premier ministre,'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>NaN</td>\n",
       "      <td>16 mars 2022.</td>\n",
       "      <td>L’action du ministère de l’intérieur est au cœ...</td>\n",
       "      <td>', 'projet de loi', '', 'Le Premier ministre,'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>271 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Information              Date  \\\n",
       "0             3     29 juin 2017.   \n",
       "1             4     29 juin 2017.   \n",
       "2             6     29 juin 2017.   \n",
       "3             7     29 juin 2017.   \n",
       "4             8     29 juin 2017.   \n",
       "..          ...               ...   \n",
       "266         NaN   2 février 2022.   \n",
       "267         NaN  23 février 2022.   \n",
       "268         NaN      7 mars 2022.   \n",
       "269         NaN      9 mars 2022.   \n",
       "270         NaN     16 mars 2022.   \n",
       "\n",
       "                                               exposee  \\\n",
       "0    L’article 114 de la loi n° 2016‑1691 du 9 déce...   \n",
       "1    Conformément à la volonté du Président de la R...   \n",
       "2    ', 'Le présent projet de loi ratifiant l’ordon...   \n",
       "3    L’article 1er du projet de loi ratifie l’ordon...   \n",
       "4    L’article unique du projet de loi procède à la...   \n",
       "..                                                 ...   \n",
       "266  L’article 74 de la loi n° 2019‑1428 du 24 déce...   \n",
       "267  L’article 55 de la loi n° 2019‑828 du 6 août 2...   \n",
       "268  ratifiant l’ordonnance n° 2021‑1200 du 15 sept...   \n",
       "269  L’article 108 de la loi n° 2020‑1576 du 14 déc...   \n",
       "270  L’action du ministère de l’intérieur est au cœ...   \n",
       "\n",
       "                                            texte_lois  \n",
       "0    ', '– 1 –', '', 'projet de loi', '', 'Le Premi...  \n",
       "1    ', '– 1 –', '', 'projet de loi', '', 'Le Premi...  \n",
       "2    ', 'projet de loi', '', 'Le Premier ministre,'...  \n",
       "3    ', '– 1 –', '', 'projet de loi', '', 'Le Premi...  \n",
       "4    ', 'projet de loi', '', 'Le Premier ministre,'...  \n",
       "..                                                 ...  \n",
       "266  ', 'projet de loi', '', 'Le Premier ministre,'...  \n",
       "267  ', '– 1 –', '', 'projet de loi', '', 'Le Premi...  \n",
       "268  ', 'projet de loi', '', 'Le Premier ministre,'...  \n",
       "269  ', 'projet de loi', '', 'Le Premier ministre,'...  \n",
       "270  ', 'projet de loi', '', 'Le Premier ministre,'...  \n",
       "\n",
       "[271 rows x 4 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.replace(regex=[r'\\[\\''], value='').replace(regex=[r'\\'\\]\\\"'], value='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "class TextInformation:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        response = requests.get(self.url)\n",
    "        self.soup = BeautifulSoup(\n",
    "            response.text,\n",
    "            'html.parser',\n",
    "            from_encoding='utf-8')\n",
    "\n",
    "    def get_information(self):\n",
    "        \"\"\"Get the information from the webpage\"\"\"\n",
    "        try:\n",
    "            soup = self.soup\n",
    "            # On a déjà stocké self.soup dans l'initialisation, on peut donc le réutiliser directement\n",
    "            information = self.soup.find('span', {'style': 'vertical-align:3pt'})\n",
    "\n",
    "            next_sibling = information.next_sibling\n",
    "            if next_sibling is not None:\n",
    "                try:\n",
    "                    return next_sibling.text.strip()\n",
    "                except AttributeError:\n",
    "                    pass\n",
    "            else:\n",
    "                print(\"Error: next sibling is None\")\n",
    "        except BaseException:\n",
    "            print(f\"Error getting information from {self.url}\")\n",
    "\n",
    "    def get_date(self):\n",
    "        date = self.soup.find('p', {'class': 'assnatenregistr'})\n",
    "\n",
    "        if date:\n",
    "            date_text = date.text.strip()\n",
    "            words = date_text.split(\" \")\n",
    "            day = words[-3]\n",
    "            month = words[-2]\n",
    "            year = words[-1]\n",
    "            return f\"{day} {month} {year}\"\n",
    "        return None\n",
    "\n",
    "    def get_texts(self):\n",
    "        texts = self.soup.find_all('p', {'class': 'assnatLoiTexte'})\n",
    "        if texts:\n",
    "            return [text.text.strip() for text in texts]\n",
    "        return None\n",
    "    \n",
    "    def get_helo(self):\n",
    "        section3 = self.soup.find('div', {'class': 'assnatSection3'})\n",
    "        if section3:\n",
    "            return   [text.text.strip() for text in section3]\n",
    "        return None\n",
    "    \n",
    "class DataCleaner:\n",
    "    def __init__(self, input_file, output_file):\n",
    "        self.input_file = input_file\n",
    "        self.output_file = output_file\n",
    "        \n",
    "    def clean_data(self):\n",
    "        # lecture des données\n",
    "        data = pd.read_csv(self.input_file)\n",
    "        to_analz_2 = data.replace(regex=[r'\\\"\\[\\''], value='').replace(regex=[r'\\'\\]\\\"'], value='').replace(regex=[r'\\\\xa0'], value=' ')\n",
    "\n",
    "        # suppression du fichier existant s'il existe\n",
    "        if os.path.exists(self.output_file):\n",
    "            os.remove(self.output_file)\n",
    "\n",
    "        # appliquer la même transformation sur to_analz_2\n",
    "        to_analz_2 = to_analz_2.replace(regex=[r'\\\"\\[\\''], value='').replace(regex=[r'\\'\\]\\\"'], value='').replace(regex=[r'\\\\xa0'], value=' ')\n",
    "\n",
    "        # enregistrement des données nettoyées dans un nouveau fichier csv\n",
    "        to_analz_2.to_csv(self.output_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "class WebScraper:\n",
    "    def __init__(self, urls):\n",
    "        self.urls = urls\n",
    "        self.result = []\n",
    "        \n",
    "    def scrape(self):\n",
    "        for url in tqdm(self.urls):\n",
    "            print(\"Processing: \", url)\n",
    "            text_info = TextInformation(url)\n",
    "            information = text_info.get_information()\n",
    "            date = text_info.get_date()\n",
    "            texts = text_info.get_texts()\n",
    "            helo = text_info.get_helo()\n",
    "            self.result.append({\n",
    "                'url': url,\n",
    "                'information': information,\n",
    "                'date': date,\n",
    "                'texts': texts,\n",
    "                'helo': helo\n",
    "            })\n",
    "            time.sleep(0.1) # Pause de 0.1 seconde entre chaque requête pour éviter de surcharger le serveur\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]/Users/camille/repo/notebook_env/lib/python3.10/site-packages/bs4/__init__.py:226: UserWarning: You provided Unicode markup but also provided a value for from_encoding. Your from_encoding will be ignored.\n",
      "  warnings.warn(\"You provided Unicode markup but also provided a value for from_encoding. Your from_encoding will be ignored.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0000.html\n",
      "Error getting information from https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0000.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:00<00:07,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0001.html\n",
      "Error getting information from https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0001.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [00:00<00:06,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0002.html\n",
      "Error getting information from https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0002.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [00:00<00:05,  4.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0003.html\n",
      "Processing:  https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0004.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [00:01<00:05,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0005.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [00:01<00:08,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error getting information from https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0005.html\n",
      "Processing:  https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0006.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/30 [00:01<00:07,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0007.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8/30 [00:02<00:06,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0008.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [00:02<00:04,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0009.html\n",
      "Processing:  https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0010.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [00:02<00:04,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0011.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 12/30 [00:02<00:03,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0012.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [00:03<00:03,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0013.html\n",
      "Processing:  https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0014.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15/30 [00:03<00:03,  4.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0015.html\n",
      "Error getting information from https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0015.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16/30 [00:03<00:03,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0016.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 17/30 [00:04<00:02,  4.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0017.html\n",
      "Error getting information from https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0017.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18/30 [00:04<00:02,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0018.html\n",
      "Error getting information from https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0018.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [00:04<00:02,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0019.html\n",
      "Error getting information from https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0019.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [00:04<00:02,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0020.html\n",
      "Error getting information from https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0020.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [00:04<00:02,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0021.html\n",
      "Error getting information from https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0021.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [00:05<00:01,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0022.html\n",
      "Error getting information from https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0022.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 23/30 [00:05<00:01,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0023.html\n",
      "Error getting information from https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0023.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24/30 [00:05<00:01,  4.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0024.html\n",
      "Error getting information from https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0024.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25/30 [00:05<00:01,  4.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0025.html\n",
      "Error getting information from https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0025.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26/30 [00:06<00:00,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0026.html\n",
      "Error getting information from https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0026.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 27/30 [00:06<00:00,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0027.html\n",
      "Error getting information from https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0027.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 28/30 [00:06<00:00,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0028.html\n",
      "Error getting information from https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0028.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29/30 [00:06<00:00,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0029.html\n",
      "Error getting information from https://www.assemblee-nationale.fr/dyn/opendata/PRJLANR5L15B0029.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:07<00:00,  4.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# create a WebScraper instance with a list of URLs to scrape\n",
    "scraper = WebScraper(urls)\n",
    "\n",
    "# call the scrape() method to scrape the URLs\n",
    "scraper.scrape()\n",
    "\n",
    "\n",
    "# create a DataFrame from the scraper result\n",
    "df = pd.DataFrame(scraper.result)\n",
    "\n",
    "# save the DataFrame to a CSV file\n",
    "df.to_csv('scraped_data.csv', index=False)\n",
    "cleaner = DataCleaner('scraped_data.csv', 'cleaned_data.csv')\n",
    "cleaner.clean_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataCleaner' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/camille/repo/Hetic/projet_demo/ia_theme_French National Assembly/scraping/projet_lois.ipynb Cell 21\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/camille/repo/Hetic/projet_demo/ia_theme_French%20National%20Assembly/scraping/projet_lois.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m cleaner \u001b[39m=\u001b[39m DataCleaner(\u001b[39m'\u001b[39m\u001b[39mscraped_data.csv\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcleaned_data.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/camille/repo/Hetic/projet_demo/ia_theme_French%20National%20Assembly/scraping/projet_lois.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m cleaner\u001b[39m.\u001b[39mclean_data()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DataCleaner' is not defined"
     ]
    }
   ],
   "source": [
    "cleaner = DataCleaner('scraped_data.csv', 'cleaned_data.csv')\n",
    "cleaner.clean_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'DataCleaner'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/camille/repo/Hetic/projet_demo/ia_theme_French National Assembly/scraping/projet_lois.ipynb Cell 22\u001b[0m in \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/camille/repo/Hetic/projet_demo/ia_theme_French%20National%20Assembly/scraping/projet_lois.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# create a DataFrame from the scraper result\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/camille/repo/Hetic/projet_demo/ia_theme_French%20National%20Assembly/scraping/projet_lois.ipynb#X30sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/camille/repo/Hetic/projet_demo/ia_theme_French%20National%20Assembly/scraping/projet_lois.ipynb#X30sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mDataCleaner\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/camille/repo/Hetic/projet_demo/ia_theme_French%20National%20Assembly/scraping/projet_lois.ipynb#X30sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(scraper\u001b[39m.\u001b[39mresult)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/camille/repo/Hetic/projet_demo/ia_theme_French%20National%20Assembly/scraping/projet_lois.ipynb#X30sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# clean the data and save to a new CSV file\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'DataCleaner'"
     ]
    }
   ],
   "source": [
    "# create a DataFrame from the scraper result\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(scraper.result)\n",
    "\n",
    "# clean the data and save to a new CSV file\n",
    "cleaner = DataCleaner('scraped_data.csv', 'cleaned_data.csv')\n",
    "cleaner.clean_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scraper'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/camille/repo/Hetic/projet_demo/ia_theme_French National Assembly/scraping/projet_lois.ipynb Cell 23\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/camille/repo/Hetic/projet_demo/ia_theme_French%20National%20Assembly/scraping/projet_lois.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mscraper\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scraper'"
     ]
    }
   ],
   "source": [
    "import scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scraper'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/camille/repo/Hetic/projet_demo/ia_theme_French National Assembly/projet_lois.ipynb Cell 24\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/camille/repo/Hetic/projet_demo/ia_theme_French%20National%20Assembly/projet_lois.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mscraper\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/camille/repo/Hetic/projet_demo/ia_theme_French%20National%20Assembly/projet_lois.ipynb#X32sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Define a list of URLs to scrape\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/camille/repo/Hetic/projet_demo/ia_theme_French%20National%20Assembly/projet_lois.ipynb#X32sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m my_urls \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mhttps://example.com/page1\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mhttps://example.com/page2\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mhttps://example.com/page3\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scraper'"
     ]
    }
   ],
   "source": [
    "import scraper\n",
    "\n",
    "\n",
    "# Define a list of URLs to scrape\n",
    "my_urls = ['https://example.com/page1', 'https://example.com/page2', 'https://example.com/page3']\n",
    "\n",
    "# Create a new instance of WebScraper and scrape the data\n",
    "my_scraper = WebScraper(my_urls)\n",
    "my_scraper.scrape()\n",
    "\n",
    "# Access the scraped data\n",
    "for data in my_scraper.result:\n",
    "    print(data['url'])\n",
    "    print(data['information'])\n",
    "    print(data['date'])\n",
    "    print(data['texts'])\n",
    "    print(data['helo'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "41fba93d83b61576bfa0d097f4901b85ad577ef97b7c4e28015daf92554e79fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
